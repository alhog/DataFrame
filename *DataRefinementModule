from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.model_selection import train_test_split
import numpy as np
from loguru import logger
import pandas as pd

class DataRefinementTask:
    def __init__(self, config):
        self.config = config

    def refine(self, data, target=None):
        raise NotImplementedError

class DataNormalizer(DataRefinementTask):
    def refine(self, data, target=None):
        logger.info(f"Normalizing data using {self.config['normalization_method']} method")
        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns

        if self.config['normalization_method'] == 'minmax':
            scaler = MinMaxScaler()
        elif self.config['normalization_method'] == 'zscore':
            scaler = StandardScaler()
        else:
            raise ValueError(f"Invalid normalization method: {self.config['normalization_method']}")

        for col in numeric_cols:
            data[col] = scaler.fit_transform(data[col].values.reshape(-1, 1))

        return data

class DimensionalityReducer(DataRefinementTask):
    def refine(self, data, target=None):
        logger.info(f"Performing dimensionality reduction using {self.config['dimensionality_reduction_method']} method")
        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns

        if self.config['dimensionality_reduction_method'] == 'pca':
            reducer = PCA(n_components=self.config['n_components'])
        else:
            raise ValueError(f"Invalid dimensionality reduction method: {self.config['dimensionality_reduction_method']}")

        reduced_data = reducer.fit_transform(data[numeric_cols])
        reduced_df = pd.DataFrame(reduced_data, columns=[f'component_{i}' for i in range(reduced_data.shape[1])])

        data = pd.concat([data, reduced_df], axis=1)
        data = data.drop(numeric_cols, axis=1)

        return data

class FeatureSelector(DataRefinementTask):
    def refine(self, data, target):
        logger.info(f"Performing feature selection using {self.config['feature_selection_method']} method")
        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns

        if self.config['feature_selection_method'] == 'kbest':
            selector = SelectKBest(f_classif, k=self.config['n_features'])
        else:
            raise ValueError(f"Invalid feature selection method: {self.config['feature_selection_method']}")

        selected_features = selector.fit_transform(data[numeric_cols], target)
        selected_df = pd.DataFrame(selected_features, columns=numeric_cols[selector.get_support()])

        data = pd.concat([data, selected_df], axis=1)
        data = data.drop(numeric_cols, axis=1)

        return data

class DataPartitioner(DataRefinementTask):
    def refine(self, data, target):
        logger.info(f"Partitioning data into train and test sets (test_size={self.config['test_size']})")

        if self.config['stratify']:
            train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=self.config['test_size'], stratify=target)
        else:
            train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=self.config['test_size'])

        return train_data, test_data, train_target, test_target

class DataRefinementModule:
    def __init__(self, config):
        self.config = config
        self.tasks = [
            DataNormalizer(config),
            DimensionalityReducer(config),
            FeatureSelector(config),
            DataPartitioner(config)
        ]

    def refine_data(self, data, target):
        # Data refinement pipeline
        for task in self.tasks[:-1]:
            data = task.refine(data, target)
        train_data, test_data, train_target, test_target = self.tasks[-1].refine(data, target)
        return train_data, test_data, train_target, test_target

# Example usage
config = {
    'normalization_method': 'minmax',
    'dimensionality_reduction_method': 'pca',
    'n_components': 10,
    'feature_selection_method': 'kbest',
    'n_features': 20,
    'test_size': 0.2,
    'stratify': True
}

refinement_module = DataRefinementModule(config)
train_data, test_data, train_target, test_target = refinement_module.refine_data(enriched_data, target_data)
